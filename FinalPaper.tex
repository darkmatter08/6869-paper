\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
\setcounter{page}{4321}
\begin{document}

%%%%%%%%% TITLE
\title{Detecting Transformation Specific Units in Deep Text CNNs}

\author{First Author\\
Institution1\\
Institution1 address\\
{\tt\small firstauthor@i1.org}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Second Author\\
Institution2\\
First line of institution2 address\\
{\tt\small secondauthor@i2.org}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
   Deep convolutional neural networks have recently demonstrated great success in computer vision problems. While there have been several efforts to understand how how these networks work, we are still far from truth. Moreover, most of the expoloratory work done has been in the domain of understanding object and scene detectors. Our motivation here is two fold - expanding the domain of standard network visualization techniques to the domain of text recognition, and most importantly, suggesting new general purpose visualization pipelines which rely on identifying subnetworks which may be performing a high level function, as opposed to the standard per unit visualization. Such subnetwork identification methods may even be useful in reducing network complexity when invariants of the system are known, and in facilitating transfer learning across different domains of computer vision. 
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
have been shown to provide state of the art performance in various computer vision tasks.  For applications ranging from object detect \cite{}, segmentation \cite{}, text recognition \cite{}, and more they have proven to be a staple in the computer vision community. Their success can be partially attributed to the networks ability to learn invariants in the high dimensional space \cite{}. Despite the successes of CNNs, they suffer from acting like a black box. Without a firm understanding of what the CNN is doing, it becomes hard to improve and optimize network typologies and techniques without trial and error. To tackle these problems, work has been done to visualize what is happening inside of the network. Despite insightful visualizations, some aspects of the network operate on modalities that cannot be directly visualized. In particular, transformations such as scaling, rotation, and translation have not been visualized in networks. We propose a method akin to how a neurologist would map out the brain by mapping out regions of activity what performing specific tasks.\cite{} By applying this technique to neural nets we can effectively map out the network.

One of the reasons CNNs have recently become popular is because we now possess the computational power to solve these large problems. Despite these advances, training and testing neural networks is a timely and expensive task compared traditional software development. We propose a method to optimize running and training CNNs in certain contexts using our visualization tool. More specifically, If a general network is trained to capture many variables (like translation and rotation), we can prune this network while maintaining accuracy if we know one of the variables is fixed. This would decrease the amount of computations necessary  at run time. In addition, the programmer can train the network once, then extract various specialized networks for more specific tasks.

We experimentally demonstrate the our visualization technique for transformations by using a network trained to read text in the wild. With the visualizations we show that it is possible to reduce the network size while retaining accuracy if transformation assumptions are made on the text.

\subsection{Main Contributions}

\begin{enumerate}
\item A visualization technique to determine activity in a network.

\item A method of reducing network complexity while retaining accuracy when assumptions on the data can be made.

\item An efficient system to create multiple specialized networks out a larger pretrained network.

\item A demonstration of detecting an removing transformation specific units in a network.
\end{enumerate}

\subsection{Main Limitations}
Our visualization technique can be useful for visualizing the network if the units of interest exist in the convolutional layers. If instead they exist in the fully connected layers, not much useful information can be extracted. In addition it is difficult to apply isolated pruning without effecting the entire network.

Another limitation is that pruning the networks graphs may not have a computational boost on hardware that are designed to work with large amount of vectors in parallel, such as GPUs. However, as machine learning becomes more prevalent, applications that utilize lower powered simpler devices will increase and benefit from the computation reduction.

\section{Related Work}
\subsection{CNN Visualization}


Torabla

\subsection{Text Recognition}

Oxford

\subsection{Transfer learning}

maybe? if we want to talk about tuning our network for different text tasks

\section{Datasets and Model}
\subsection{DATASETS}
Talk about MJSynth and Synthetic dataset we generated. 

\subsection{Synthetic text generation pipeline}

\subsection{NIPS15 model}
Describe charnet and oxford pipeline

\subsection{Model Validation}
Give numbers on model validation for MatConvnet and Caffe implementation.

\subsection{Dropping Neurons}
How we choose what and when to drop neurons

\section{Visualization Pipelines}

\subsection{Deep Visualization Toolbox by yosinski et al}

\subsection{Visualizing filter activations}

\subsection{Network architecture invariants - Top Weights Method}

\subsection{Location encoding in networks - Patch Method}

\subsection{Subnetwork Identification from Activations}


\section{Results}

\subsection{Detecting Transformation Specific Units}
Show that we can detect transformation units.

\begin{figure}
%\includegraphics[width=\columnwidth]{}
\caption{Comparison of activations for different transformations}
\label{fig:comp}
\end{figure}

\subsection{Dropping Transformation Specific Units}
Show that we retain (or don't) accuracy if we drop units

\begin{figure}
%\includegraphics[width=\columnwidth]{}
\caption{Plot of accuracy decrease as neurons are removed}
\label{fig:comp}
\end{figure}

%-------------------------------------------------------------------------
\section{Discussion}

\subsection{Better understanding of Deep CNNS}
Talk about why this helps us understand what Deep CNNs are doing

%-------------------------------------------------------------------------
\subsection{Transfer Learning}

Talk about how this can better inform transfer learning because we know what is doing what

%-------------------------------------------------------------------------
\subsection{Reducing Computational Complexity}
Talk about why this pruning process may be useful to improve run times on mobile devices (or non GPU devices).

%-------------------------------------------------------------------------
\subsection{Conclusion}


%------------------------------------------------------------------------

{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\end{document}
